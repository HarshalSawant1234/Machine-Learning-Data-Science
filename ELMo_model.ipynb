{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ELMo_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDYJ4ijRiIgi",
        "colab_type": "code",
        "outputId": "57e79ba1-4796-4beb-9522-52d52b11f2c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#!python -m spacy download en_core_web_lg\n",
        "#!pip3 install --upgrade --force-reinstall tensorflow-gpu==1.9.0 --user\n",
        "#!pip3 install --upgrade tensorflow\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5wMBOrlmD26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import time\n",
        "import pickle\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords # corpus implies collection of words of same type\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "#nlp= spacy.load('en_core_web_lg')\n",
        "#nlp.Defaults.stop_words.add('s')\n",
        "#nlp.vocab['s'].is_stop=True\n",
        "\n",
        "#nlp.max_length = 5198623\n",
        "dataset = pd.read_excel('Data_Train.xlsx',delimiter='\\t',quoting=3)\n",
        "testing_data = pd.read_excel('Data_Test.xlsx',delimiter='\\t',quoting=3)\n",
        "#quoting = 3 for ignoring the double quotes\n",
        "\n",
        "\n",
        "\n",
        "corpus = []\n",
        "\n",
        "for i in range(0,7628):\n",
        "    review = re.sub('[^a-zA-Z]',' ',dataset['STORY'][i])\n",
        "    # re.sub function with ^ only keeps character and removes all the punctuation\n",
        "    #' '= space so that two words dont joint\n",
        "    review = review.lower()\n",
        "    # lowercase character\n",
        "    review = review.split()\n",
        "    # to convert string into list\n",
        "    ps = PorterStemmer()\n",
        "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    # set for faster execution\n",
        "    # checking irrelevant words in stopwords e.g this\n",
        "    # PorterStemmer converts 'loved' into 'love' into their original stem\n",
        "\n",
        "    review = ' '.join(review) \n",
        "    # convert the list into string again. # ' ' - so that words dont join\n",
        "    corpus.append(review) # to append the review to the corpus list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1ux42d4kP0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus1 = []\n",
        "for i in range(0,2748):\n",
        "    review1 = re.sub('[^a-zA-Z]',' ',testing_data['STORY'][i])\n",
        "    review1 = review1.lower()\n",
        "    review1 = review1.split()\n",
        "    ps1 = PorterStemmer()\n",
        "    review1 = [ps1.stem(word1) for word1 in review1 if not word1 in set(stopwords.words('english'))]\n",
        "    review1 = ' '.join(review1) \n",
        "    corpus1.append(review1) # to append the review to the corpus list\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsCuS3T9nc7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "\n",
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvgEovAJo7YI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def elmo_vectors(x):\n",
        "  embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "    # return average of ELMo features\n",
        "    return sess.run(tf.reduce_mean(embeddings,1))\n",
        "                           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuxKPDo2quiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = np.array(corpus)\n",
        "corpus1 = np.array(corpus1)\n",
        "list_train = [corpus[i:i+100] for i in range(0,corpus.shape[0],100)]\n",
        "list_test = [corpus1[i:i+100] for i in range(0,corpus1.shape[0],100)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWuDcx-Jr2KB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract ELMo embeddings\n",
        "elmo_train = [elmo_vectors(x) for x in list_train]\n",
        "elmo_test = [elmo_vectors(x) for x in list_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKH5NMH9QVA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save elmo_train_new\n",
        "elmo_train_new = np.concatenate(elmo_train, axis = 0)\n",
        "elmo_test_new = np.concatenate(elmo_test, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eayEE0-RGxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save elmo_train_new\n",
        "pickle_out = open(\"elmo_train_03032019.pickle\",\"wb\")\n",
        "pickle.dump(elmo_train_new, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "# save elmo_test_new\n",
        "pickle_out = open(\"elmo_test_03032019.pickle\",\"wb\")\n",
        "pickle.dump(elmo_test_new, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42CV4C9qRdeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "# load elmo_train_new\n",
        "pickle_in = open(\"elmo_train_03032019.pickle\", \"rb\")\n",
        "elmo_train_new = pickle.load(pickle_in)\n",
        "\n",
        "# load elmo_train_new\n",
        "pickle_in = open(\"elmo_test_03032019.pickle\", \"rb\")\n",
        "elmo_test_new = pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPPOXuPERhdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_excel('Data_Train.xlsx',delimiter='\\t',quoting=3)\n",
        "y = dataset.iloc[:,1].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyPO9s_BSLeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apGc8yYdpklK",
        "colab_type": "code",
        "outputId": "4d8b291e-6690-42b3-e76c-14dee87cadfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier1 = RandomForestClassifier(n_estimators = 300, criterion = 'entropy', random_state = 0)\n",
        "classifier1.fit(elmo_train_new, y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u-h3oKFSnos",
        "colab_type": "code",
        "outputId": "31b6babc-5f37-4609-ceb6-61d4fcad13f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = classifier1.predict(elmo_test_new)\n",
        "\n",
        "submission = pd.DataFrame({'SECTION':y_pred})\n",
        "filename = 'prediction_news.xlsx'\n",
        "submission.to_excel(filename,index=False)\n",
        "print('Saved file: ' + filename)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved file: prediction_news.xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBXXaTbwqIrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --upgrade tensorflow_gpu==1.5.0\n",
        "#!nvcc --version\n",
        "#!apt-get install cuda-libraries-9-0"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}